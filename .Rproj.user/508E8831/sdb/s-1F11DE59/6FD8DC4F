{
    "contents" : "require(shiny)\nrequire(markdown)\n\nshinyUI(\n    navbarPage(\"Coursera NLP Capstone\", inverse = FALSE, collapsible = FALSE, \n               tabPanel(\"Prediction\", \n                        fluidRow(\n                            sidebarPanel(width=3,\n                                         h5(\"Text Input:\"),\n                                         textInput(\"entry\", \n                                                   \"After initial loading (which takes about 8 seconds) this app will predict the next word in the sentence enterd below:\",\n                                                   \"Thanks for stopping by\"),\n                                         # submitButton('Predict'),\n                                         ## sliderInput(\"max\", \n                                                     ## h5(\"Maximum Number of Words:\"), \n                                                     ## min = 10,  max = 200,  value = 100),\n                                         br(),\n                                         ## actionButton(\"update\", \"Update Word Cloud\"),\n                                         hr(),\n                                         helpText(h5(\"Help Instruction:\")),\n                                         helpText(\"To predict the nesxt word in the sentence:\"),\n                                         helpText(\"1. Type your sentence in the text field\", style=\"color:#428ee8\"),\n                                         helpText(\"2. The value will be passed to the model while you are typing.\", style=\"color:#428ee8\"),\n                                         helpText(\"3. Obtain the predictions below.\", style=\"color:#428ee8\"),\n                                         hr(),\n                                         helpText(h5(\"Note:\")),\n                                         helpText(\"\n                                                  After the app is 100% loaded you will see the prediction\n                                                  for the default sentence example \\\"Thanks for stopping by\\\"\n                                                  on the right side.\"),\n                                         hr(),\n                                         h6(\"This App is built for:\"),\n                                         a(\"Coursera Data Science Capstone\", href=\"https://www.coursera.org/course/dsscapstone\"),\n                                         p(\"class started on 9 March 2015\"),\n                                         hr(),\n                                         ##h6(\"For more information about Ben Apple:\"),\n                                         ##a(img(src = \"GitHub-Mark.png\", height = 30, width = 30),href=\"https://github.com/bengapple/Swiftkey_Capstone\"),\n                                         ##a(img(src = \"linkedin.png\", height = 26, width = 26),href=\"https://www.linkedin.com/in/ivanliu1989\"),\n                                         ##a(img(src = \"gmail.jpeg\", height = 30, width = 30),href=\"mailto: ivan.liuyanfeng@gmail.com\"),\n                                         br()\n                                         ),\n                            mainPanel(\n                                column(5,\n                                       h3(\"Word Prediction\"),hr(),\n                                       h5('The sentence you just typed:'),                             \n                                       wellPanel(span(h4(textOutput('sent')),style = \"color:#428ee8\")),\n                                       hr(),\n                                       h5('Single Word Prediction:'),\n                                       wellPanel(span(h4(textOutput('top1')),style = \"color:#e86042\")),\n                                       hr(),\n                                       h5('Other Possible Single Word Predictions:'),\n                                       wellPanel(span(h5(textOutput('top2')),style = \"color:#2b8c1b\"),\n                                                 span(h5(textOutput('top3')),style = \"color:#2b8c1b\"),\n                                                 span(h5(textOutput('top4')),style = \"color:#2b8c1b\"),\n                                                 span(h5(textOutput('top5')),style = \"color:#2b8c1b\")),\n                                       hr(),\n                                       \n                                       p()\n                                ),\n                                column(5,\n                                       h3(\" \"),\n                                       \n                                       # plotOutput(\"wordCloud\"), # wordcloud\n                                       br()\n                                 )\n                                )\n                            )\n               ),\n               tabPanel(\"Model/Algorithm\",\n                        sidebarLayout(\n                            sidebarPanel(width=3,\n                                         helpText(h5(\"Help Instruction:\")),\n                                         helpText(\"Please switch the panels on the right side to figure out:\"),\n                                         helpText(\"1. How is the word being predicted?\", style=\"color:#428ee8\"),\n                                         helpText(\"2. How does this App work?\", style=\"color:#428ee8\"),\n                                         helpText(\"3. Key concepts / techniques implemented in model\", style=\"color:#428ee8\"),\n                                         hr(),\n                                         helpText(h5(\"Note:\")),\n                                         helpText(\"For more information, you can go to\", code(\"Documents tab\"), \"in the navi bar\n                                                  to read relevant intrim report and final report of this data product.\"),\n                                         hr(),\n                                         h6(\"This App is built for:\"),\n                                         a(\"Coursera Data Science Capstone\", href=\"https://www.coursera.org/course/dsscapstone\"),\n                                         p(\"class started on 9 March 2015\"),\n                                         hr(),\n                                         ##h6(\"For more information about Ben Apple:\"),\n                                         ##a(img(src = \"GitHub-Mark.png\", height = 30, width = 30),href=\"https://github.com/bengapple/Swiftkey_Capstone\"),\n                                         ##a(img(src = \"linkedin.png\", height = 26, width = 26),href=\"https://www.linkedin.com/in/ivanliu1989\"),\n                                         ##a(img(src = \"gmail.jpeg\", height = 30, width = 30),href=\"mailto: ivan.liuyanfeng@gmail.com\"),\n                                         br(),hr()\n                                         ),\n                            mainPanel(\n                                tabsetPanel(type=\"tabs\",\n                                            tabPanel(\"Predictive Model\",                                                      \n                                                     h3(\"Predictive Model Establishment\"),hr(),\n                                                     h4(\"Clean the training dataset\"),\n                                                     p(\"The dataset was cleaned using the tokenization and ngramify\n                                                       functions. They are able to help users tokenize and ngramify\n                                                       the text data in an automatic way and allow user to split large datasets into a number of\n                                                       user defined small ones in order to reduce the processing time and avoid the \n                                                       memory limits inherent to R\"),\n                                                     p(\"The raw text datasets are about 580M in total- en_US.blogs.txt-210M,\n                                                       en_US.news.txt-206M, and en_US.twitter.txt-167M\"),\n                                                     p(\"After the preprocessing to the datasets including cleaning, tokenizing and ngramifing, \n                                                       the three raw datasets are combined and then 1-4 grams frequency matrix are built. \n                                                       The total size of new dataset is reduced to 36M.\"),\n                                                     hr(),\n                                                     h4(\"Build the model\"),\n                                                     p(a(\"Simple Good-Turing\", href = \"https://class.coursera.org/nlp/lecture/32\"),\n                                                       'and Back off techniques were used for estimating the probabilities corresponding to the observed frequencies, \n                                                       and the joint probability of all unobserved species. The last three words of users\\' input sentence will be extracted first and used\n                                                       for seach in 4-grams matrix. If none result is return, then we will move back to 3-grams, and then 2-grams and 1-gram.\n                                                       the final predictions will be chosen accordingly by the frequency and n-grams of the model.' ),                                                         \n                                                     hr(),\n                                                     ## h4(\"A glance of model table\"),\n                                                     ## dataTableOutput('modelTable'),\n                                                     br(),\n                                                     br()\n                                                     ),\n                                            \n                                            tabPanel(\"App Workflow\",                                                       \n                                                     h3(\"Shiny App Prediction Algorithm\"),\n                                                     hr(),\n                                                     img(src=\"work_flow_shiny.png\", height = 262, width = 800),\n                                                     hr(),\n                                                     h4(\"Preprocess\"),\n                                                     p(\"1. Obtain the data from the input box.\"),\n                                                     p(\"2. Cleaning for the data sentence. Numbers, punctuations,\n                                                       extra spaces will be removed, and all words are converted to lowercase.\"),\n                                                     hr(),\n                                                     h4(\"Tokenize\"),\n                                                     p(\"After preprocessing, the sentence will be truncated from the last 3 words.\n                                                       , If there are less than 3 words, all the words will be used.\"),\n                                                     hr(),\n                                                     h4(\"Search pattern\"),\n                                                     p(\"Search the pattern from the n-gram model \n                                                       The algormithm will search the pattern from \n                                                       the 3-grams frequency matrix, and then return the Top 5 frequent predictions.However, \n                                                       if there is no result, it will automatically search the 2-grams, \n                                                       and if it still no result, it will search the 1-gram matrix.\"),\n                                                     hr(),\n                                                     h4(\"Predict the next single word\"),\n                                                     p(\"The next possible single word will be returned and displayed. \n                                                       In addition, the top 5 possible words also could be found. The average predicting time for\n                                                       one input is usually 0.000 ~ 0.003s.\")\n                                                     ),\n                                            \n                                            tabPanel(\"Key Concepts\",                                                      \n                                                     h3(\"Key Concepts/Terminology\"),hr(),\n                                                     h4(\"1. Tokenization() function\"),\n                                                     p(\"Tokenization(), function based on the tm R Packagepackage\n                                                       for data cleanning process, it mainly provides users with reproducible functionalities such as:,\n                                                       Simple Transformation, Lowercase Transformation, the removal of Numbers and \n                                                       Punctuations and removeing Stop Words and perfoming Profanity Filtering with only one command.\"),\n                                                     hr(),\n                                                     h4(\"2. ngramify() function\"),\n                                                     p(\"ngramify(), function tackle the memory limits problem when generating\n                                                       ngrams model from database. It provides users with a reproducible functionality to split raw datasets into a bunch of\n                                                       user defined number of small ones and transform them into n-grams model.\"),\n                                                     hr(),\n                                                     h4(\"3. N-grams language model\"),\n                                                     p(\"An n-gram model is a type of probabilistic language model for predicting the next item in such a sequence in the form of \n                                                       a (n - 1) –order Markov model\"),\n                                                     p(\"In this model, we are using 1-4 grams for prediction purpose, they are refering to unigram,\n                                                       bigram, trigram, and quatrgram respectively.\"),\n                                                     hr(),\n                                                     h4(\"4. Computing probabilities\"),\n                                                     p(\"To compute the probabilities of each token,\",a(\"Markov chain\", href=\"http://en.wikipedia.org/wiki/Markov_chain\"),\"is introduced and implemented\n                                                       in our model.\"),\n                                                     p(\"A Markov chain is a sequence of random variables X1, X2, X3, ... with the Markov property, namely that, \n                                                       given the present state, the future and past states are independent. Formally,\"),\n                                                     img(src = \"markov.png\", height = 20),\n                                                     hr(),\n                                                     h4(\"5. Smoothing\"),\n                                                     p(\"Smoothing techniques are main used to cope with unseen n-grams in text modelling.\",\n                                                       a(\"Katz's back-off model\", href=\"http://en.wikipedia.org/wiki/Katz%27s_back-off_model\"),\"is introduced in our model.\"),\n                                                     p(\"Katz back-off is a generative n-gram language model that estimates the conditional probability of a word given its history \n                                                       in the n-gram. It accomplishes this estimation by \\\"backing-off\\\" to models with smaller histories under certain conditions. \n                                                       By doing so, the model with the most reliable information about a given history is used to provide the better results.\"),\n                                                     p(\"The equation for Katz's back-off model is:\"),\n                                                     img(src = \"backoff.png\"),\n                                                     br(),hr()\n                                                     )\n                                                     )\n                                                     )\n                                                     )\n                                                     ),\n               navbarMenu(\"Documents\",\n                          tabPanel(\"Interim Report\",\n                                   sidebarLayout(\n                                       sidebarPanel(width=3,\n                                                    helpText(h5(\"Note:\")),\n                                                    helpText(\"This document is taken from the MidPoint report for the Capstone and explains some of the data attributes that have been identified \n                                                             and briefly summarizes the plans for creating the prediction algorithm and Shiny app in a way that\n                                                             would be understandable to a non-data scientist manager. It includes:\"),\n                                                    helpText(\"1. A basic report of summary statistics about the data sets.\", style=\"color:#428ee8\"),\n                                                    helpText(\"2. Interesting findings that author amassed so far.\", style=\"color:#428ee8\"),\n                                                    helpText(\"3. Plans for creating a prediction algorithm and Shiny app\", style=\"color:#428ee8\"),\n                                                    hr(),\n                                                    h6(\"This App is built for:\"),\n                                                    a(\"Coursera Data Science Capstone\", href=\"https://www.coursera.org/course/dsscapstone\"),\n                                                    p(\"class started on 9 March 2015\"),\n                                                    hr(),\n                                                    ##h6(\"For more information about Ben Apple:\"),\n                                                    ##a(img(src = \"GitHub-Mark.png\", height = 30, width = 30),href=\"https://github.com/bengapple/Swiftkey_Capstone\"),\n                                                    ##a(img(src = \"linkedin.png\", height = 26, width = 26),href=\"https://www.linkedin.com/in/ivanliu1989\"),\n                                                    ##a(img(src = \"gmail.jpeg\", height = 30, width = 30),href=\"mailto: ivan.liuyanfeng@gmail.com\"),\n                                                    br()),\n                                       mainPanel(\n                                           includeMarkdown('milestonerpt.md')\n                                       )\n                                       )\n                                   ),\n                          tabPanel(\"Final Report\",\n                                   sidebarLayout(\n                                       sidebarPanel(width=3,\n                                                    helpText(h5(\"Note:\")),\n                                                    helpText(\"This document is a slide deck consisting of 5 slides created with\", \n                                                             a(\"R Studio Presenter\", href=\"https://support.rstudio.com/hc/en-us/articles/200486468-Authoring-R-Presentations\"),\n                                                             \"pitching the algorithm and app for the sake of presenting to management or an investor. It includes:\"),\n                                                    helpText(\"1. A description of the algorithm used to make the prediction\", style=\"color:#428ee8\"),\n                                                    helpText(\"2. Description of app and instructions of how it functions\", style=\"color:#428ee8\"),\n                                                    helpText(\"3. Description of the experience of using this app\", style=\"color:#428ee8\"),\n                                                    hr(),\n                                                    h6(\"This App is built for:\"),\n                                                    a(\"Coursera Data Science Capstone\", href=\"https://www.coursera.org/course/dsscapstone\"),\n                                                    p(\"class started on 9 March 2015\"),\n                                                    hr(),\n                                                    ##h6(\"For more information about Ben Apple:\"),\n                                                    ##a(img(src = \"GitHub-Mark.png\", height = 30, width = 30),href=\"https://github.com/bengapple/Swiftkey_Capstone\"),\n                                                    ##a(img(src = \"linkedin.png\", height = 26, width = 26),href=\"https://www.linkedin.com/in/ivanliu1989\"),\n                                                    ##a(img(src = \"gmail.jpeg\", height = 30, width = 30),href=\"mailto: ivan.liuyanfeng@gmail.com\"),\n                                                    br()),\n                                       mainPanel(width=9,\n                                                  ## column(8,\n                                                        ## a(img(src = \"slides_1.png\"),href=\"http://rpubs.com/bengapple/71376\"),hr(),\n                                                        ## a(img(src = \"slides_2.png\"),href=\"http://rpubs.com/bengapple/71376\"),hr(),\n                                                        ## a(img(src = \"slides_3.png\"),href=\"http://rpubs.com/bengapple/71376\"),hr(),\n                                                        ## a(img(src = \"slides_4.png\"),href=\"http://rpubs.com/bengapple/71376\"),hr(),\n                                                        ## a(img(src = \"slides_5.png\"),href=\"http://rpubs.com/bengapple/71376\"),hr()\n                                                 ## ),\n                                                 column(4,\n                                                        ## h5(\"Please use the slides\", code(\"navigation bar\"), \n                                                        ##   \"on the right-bottom corner of the page.\"),\n                                                        ## hr(),\n                                                        h5(\"To browse the released version of the slide presentation,\n                                                         please visit the RPubs link below.\"),\n                                                        a(\"Capstone Presentation\", href=\"http://rpubs.com/bengapple/71376\")\n                                                 )\n                                       )\n                                   )\n                          )\n               )\n               )\n    )\n",
    "created" : 1428183156059.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "894266202",
    "id" : "6FD8DC4F",
    "lastKnownWriteTime" : 1428244571,
    "path" : "D:/RFiles/Finale_shiny_app/ui.R",
    "project_path" : "ui.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}